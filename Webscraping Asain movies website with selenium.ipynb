{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2dd9be",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6b1ba",
   "metadata": {},
   "source": [
    "### Importing the neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f505f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import urllib\n",
    "from urllib.request import urlretrieve as r\n",
    "import os\n",
    "import requests\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import binascii as ba\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementNotInteractableException \n",
    "from selenium.common.exceptions import StaleElementReferenceException, JavascriptException                     \n",
    "from requests import Request\n",
    "from urllib.request import urlopen\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver .common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ff513",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_path = 'C:/Users/Mardiyyah/Desktop/chromedriver_win32/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7439449",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=c_path)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3663ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://fixdrama.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127023a4",
   "metadata": {},
   "source": [
    "### Scraping for korean movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = driver.find_element(By.LINK_TEXT, \"KOREAN\")\n",
    "link.click()\n",
    "#navigating to korean dramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add971b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[3]/div/div[2]/div[2]/ul/li[7]/a').text\n",
    "#finding the number of pages the korean dramas appear on\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,ElementNotInteractableException,JavascriptException)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97ac60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "pages = 77\n",
    "while pages < int(page):\n",
    "#while pages < 5:\n",
    "    try:\n",
    "        driver.refresh()\n",
    "        module = WebDriverWait(driver, 10, ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.CLASS_NAME, \"block-items\")))\n",
    "        titles_count = len(module.find_elements(By.XPATH, '//div[contains(@class, \"col-xlg-2\")]'))\n",
    "        for title_idx in range(titles_count):\n",
    "            tit = driver.find_element(By.XPATH, f'//div[contains(@class, \"col-xlg-2\")][{title_idx+1}]')\n",
    "            actions.move_to_element(tit).click().perform()\n",
    "            title = driver.find_element_by_xpath('//h1[@class = \"movie-title text-nowrap\"]').text\n",
    "            rating = driver.find_element(By.XPATH, '//div[@class = \"caption\"]').text\n",
    "            genre = driver.find_element(By.XPATH, '//h2[@class = \"movie-subtitle\"]').text\n",
    "            summary = driver.find_element(By.TAG_NAME, 'p').text\n",
    "            #year = driver.find_element(By.XPATH, '//li[@class =\"common-list\"]').text\n",
    "            try:\n",
    "                driver.execute_script(\"document.getElementById('mCSB_1').scrollIntoView();\")\n",
    "                casts = set()\n",
    "                cast = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                for cat in cast:\n",
    "                    casts.add(cat.text)\n",
    "                try:\n",
    "                    slider = driver.find_element(By.CLASS_NAME, 'mCSB_dragger')\n",
    "                    actions.drag_and_drop_by_offset(slider, 0, 200).perform()\n",
    "                    crew = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                    for cre in crew:\n",
    "                        casts.add(cre.text)\n",
    "                except ignored_exceptions:\n",
    "                    pass\n",
    "            except ignored_exceptions:  #spelling error making this code not work as expected\n",
    "                casts = \"not available\"\n",
    "            data.append({\"Title\": title, \"Rating\": rating, \"Genre\": genre, \"Description\": summary, \"Casts\":casts, 'Country':'Korean'})\n",
    "            driver.back()\n",
    "            pages += 1\n",
    "            if pages <int(page):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                link = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.LINK_TEXT, \"Next »\")))\n",
    "                actions.move_to_element(link).click().perform()\n",
    "    finally:\n",
    "        print(f\"{len(data)} done\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dictionary to a dataframe\n",
    "movies_csv = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683055e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as a csv file\n",
    "movies_csv.to_csv(\"KoreanMovies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc2b3a",
   "metadata": {},
   "source": [
    "### Scraping for chinese movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigating to chinese movies on the website\n",
    "link = driver.find_element(By.LINK_TEXT, \"CHINESE\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[3]/div/div[2]/div[2]/ul/li[7]/a').text\n",
    "#finding the number of pages the chinese dramas appear on\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba911dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataC = []\n",
    "pages = 0\n",
    "while pages < int(page):\n",
    "    try:\n",
    "        driver.refresh()\n",
    "        module = WebDriverWait(driver, 10, ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.CLASS_NAME, \"block-items\")))\n",
    "        titles_count = len(module.find_elements(By.XPATH, '//div[contains(@class, \"col-xlg-2\")]'))\n",
    "        for title_idx in range(titles_count):\n",
    "            tit = driver.find_element(By.XPATH, f'//div[contains(@class, \"col-xlg-2\")][{title_idx+1}]')\n",
    "            actions.move_to_element(tit).click().perform()\n",
    "            title = driver.find_element_by_xpath('//h1[@class = \"movie-title text-nowrap\"]').text\n",
    "            rating = driver.find_element(By.XPATH, '//div[@class = \"caption\"]').text\n",
    "            genre = driver.find_element(By.XPATH, '//h2[@class = \"movie-subtitle\"]').text\n",
    "            summary = driver.find_element(By.TAG_NAME, 'p').text\n",
    "            #year = driver.find_element(By.XPATH, '//li[@class =\"common-list\"]').text\n",
    "            try:\n",
    "                driver.execute_script(\"document.getElementById('mCSB_1').scrollIntoView();\")\n",
    "                casts = set()\n",
    "                cast = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                for cat in cast:\n",
    "                    casts.add(cat.text)\n",
    "                try:\n",
    "                    slider = driver.find_element(By.CLASS_NAME, 'mCSB_dragger')\n",
    "                    actions.drag_and_drop_by_offset(slider, 0, 200).perform()\n",
    "                    crew = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                    for cre in crew:\n",
    "                        casts.add(cre.text)\n",
    "                except ignored_exceptions:\n",
    "                    pass\n",
    "            except ignored_exceptions:  #spelling error making this code not work as expected\n",
    "                casts = \"not available\"\n",
    "            dataC.append({\"Title\": title, \"Rating\": rating, \"Genre\": genre, \"Description\": summary, \"Casts\":casts, 'Country':'Chinese'})\n",
    "            driver.back()\n",
    "        pages += 1\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        if pages < int(page):\n",
    "            link = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.LINK_TEXT, \"Next »\")))\n",
    "            actions.move_to_element(link).click().perform()\n",
    "    except ignored_exceptions:\n",
    "        pass\n",
    "    finally:\n",
    "        print(f\"{len(dataC)} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dictionary to a dataframe\n",
    "movies = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as a csv file\n",
    "movies.to_csv(\"ChineseMovies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdca3bd9",
   "metadata": {},
   "source": [
    "### Scraping for HongKong movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigating to hong kong movies on the website\n",
    "link = driver.find_element(By.LINK_TEXT, \"HK DRAMA\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1936930",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[3]/div/div[2]/div[2]/ul/li[6]/a').text\n",
    "#finding the number of pages the hongkong dramas appear on\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataH = []\n",
    "pages = 0\n",
    "while pages < int(page):\n",
    "    try:\n",
    "        driver.refresh()\n",
    "        module = WebDriverWait(driver, 10, ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.CLASS_NAME, \"block-items\")))\n",
    "        titles_count = len(module.find_elements(By.XPATH, '//div[contains(@class, \"col-xlg-2\")]'))\n",
    "        for title_idx in range(titles_count):\n",
    "            tit = driver.find_element(By.XPATH, f'//div[contains(@class, \"col-xlg-2\")][{title_idx+1}]')\n",
    "            actions.move_to_element(tit).click().perform()\n",
    "            title = driver.find_element_by_xpath('//h1[@class = \"movie-title text-nowrap\"]').text\n",
    "            rating = driver.find_element(By.XPATH, '//div[@class = \"caption\"]').text\n",
    "            genre = driver.find_element(By.XPATH, '//h2[@class = \"movie-subtitle\"]').text\n",
    "            summary = driver.find_element(By.TAG_NAME, 'p').text\n",
    "            #year = driver.find_element(By.XPATH, '//li[@class =\"common-list\"]').text\n",
    "            try:\n",
    "                driver.execute_script(\"document.getElementById('mCSB_1').scrollIntoView();\")\n",
    "                casts = set()\n",
    "                cast = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                for cat in cast:\n",
    "                    casts.add(cat.text)\n",
    "                try:\n",
    "                    slider = driver.find_element(By.CLASS_NAME, 'mCSB_dragger')\n",
    "                    actions.drag_and_drop_by_offset(slider, 0, 200).perform()\n",
    "                    crew = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                    for cre in crew:\n",
    "                        casts.add(cre.text)\n",
    "                except ignored_exceptions:\n",
    "                    pass\n",
    "            except ignored_exceptions:  #spelling error making this code not work as expected\n",
    "                casts = \"not available\"\n",
    "            dataH.append({\"Title\": title, \"Rating\": rating, \"Genre\": genre, \"Description\": summary, \"Casts\":casts, 'Country':'HongKong'})\n",
    "            driver.back()\n",
    "        pages += 1\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        if pages < int(page):\n",
    "            link = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.LINK_TEXT, \"Next »\")))\n",
    "            actions.move_to_element(link).click().perform()\n",
    "    except ignored_exceptions:\n",
    "        pass\n",
    "    finally:\n",
    "        print(f\"{len(dataH)} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af64f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dictionary to a dataframe\n",
    "hk_movies = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b1be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as a csv file\n",
    "hk_movies.to_csv(\"HongKongMovies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf60f8",
   "metadata": {},
   "source": [
    "### Scraping for Thailand Movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Navigating to thailand movies on the website\n",
    "link = driver.find_element(By.LINK_TEXT, \"THAILAND\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.find_element(By.XPATH, '//*[@id=\"content\"]/div/div[3]/div/div[2]/div[2]/ul/li[7]/a').text\n",
    "#finding the number of pages the thailand dramas appear on\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd93ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataT = []\n",
    "pages = 0\n",
    "while pages < int(page):\n",
    "    try:\n",
    "        driver.refresh()\n",
    "        module = WebDriverWait(driver, 10, ignored_exceptions=ignored_exceptions).until(EC.presence_of_element_located((By.CLASS_NAME, \"block-items\")))\n",
    "        titles_count = len(module.find_elements(By.XPATH, '//div[contains(@class, \"col-xlg-2\")]'))\n",
    "        for title_idx in range(titles_count):\n",
    "            tit = driver.find_element(By.XPATH, f'//div[contains(@class, \"col-xlg-2\")][{title_idx+1}]')\n",
    "            actions.move_to_element(tit).click().perform()\n",
    "            title = driver.find_element_by_xpath('//h1[@class = \"movie-title text-nowrap\"]').text\n",
    "            rating = driver.find_element(By.XPATH, '//div[@class = \"caption\"]').text\n",
    "            genre = driver.find_element(By.XPATH, '//h2[@class = \"movie-subtitle\"]').text\n",
    "            summary = driver.find_element(By.TAG_NAME, 'p').text\n",
    "            #year = driver.find_element(By.XPATH, '//li[@class =\"common-list\"]').text\n",
    "            try:\n",
    "                driver.execute_script(\"document.getElementById('mCSB_1').scrollIntoView();\")\n",
    "                casts = set()\n",
    "                cast = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                for cat in cast:\n",
    "                    casts.add(cat.text)\n",
    "                try:\n",
    "                    slider = driver.find_element(By.CLASS_NAME, 'mCSB_dragger')\n",
    "                    actions.drag_and_drop_by_offset(slider, 0, 200).perform()\n",
    "                    crew = driver.find_elements(By.CLASS_NAME, 'actor-info')\n",
    "                    for cre in crew:\n",
    "                        casts.add(cre.text)\n",
    "                except ignored_exceptions:\n",
    "                    pass\n",
    "            except ignored_exceptions:  #spelling error making this code not work as expected\n",
    "                casts = \"not available\"\n",
    "            dataT.append({\"Title\": title, \"Rating\": rating, \"Genre\": genre, \"Description\": summary, \"Casts\":casts, 'Country':'Thailand'})\n",
    "            driver.back()\n",
    "        pages += 1\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        if pages < int(page):\n",
    "            link = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.LINK_TEXT, \"Next »\")))\n",
    "            actions.move_to_element(link).click().perform()\n",
    "    except ignored_exceptions:\n",
    "        pass\n",
    "    finally:\n",
    "        print(f\"{len(dataT)} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the dictionary to a dataframe\n",
    "thai_movies = pd.DataFrame.from_dict(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dcc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe as a csv file\n",
    "thai_movies.to_csv(\"ThaiLandMovies.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
